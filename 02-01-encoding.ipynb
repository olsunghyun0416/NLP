{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Evn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import zipfile\n",
    "import math\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed initialize\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "source": [
    "# One-hot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding text\n",
    "text = \"\"\"나는 책을 샀다\n",
    "나는 책을 본다\n",
    "나는 책을 팔았다\n",
    "나는 책을 서점에서 샀다\n",
    "나는 책을 도서관에서 본다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(dict.fromkeys(tokens))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어에 고유한 번호 부여한 dictionary 생성\n",
    "word_to_id = {'[PAD]': 0, '[UNK]': 1}  # [PAD]: 길이 맞추는 용도, [UNK]: 알 수 없는 token\n",
    "for word in words:\n",
    "    word_to_id[word] = len(word_to_id)\n",
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고유한 번호로 부터 단어를 찾을 수 있는 dictionary 생성\n",
    "id_to_word = {word:_id for _id, word in word_to_id.items()}\n",
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 줄바꿈 단위로 문장 분리\n",
    "sentences = text.split(\"\\n\")\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기 단위로 단어 분리\n",
    "tokens = []\n",
    "for sentence in sentences:\n",
    "    # print(sentence)\n",
    "    tokens.append(sentence.split())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens을 vocabulary의 고유 번호로 변경\n",
    "token_ids = []\n",
    "for line_token in tokens:\n",
    "    token_ids.append([word_to_id[token] for token in line_token])\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "one_hot_encodings = []\n",
    "for line_token in token_ids:\n",
    "    print(line_token)\n",
    "    one_hot_line = []  # 한 줄을 표현하는 벡터\n",
    "    for id in line_token:\n",
    "        ################################\n",
    "        one_hot = [0] * len(word_to_id)  # 모두 0인 벡터를 만듬\n",
    "        one_hot[id] = 1\n",
    "        print(id, one_hot)\n",
    "        one_hot_line.append(one_hot)\n",
    "        ################################\n",
    "    one_hot_encodings.append((one_hot_line))  # 라인을 전체 문서에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.array(one_hot_encodings[4]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow one hot\n",
    "# token_ids가 앞 3개는 길이가 3 이지만 이후는 4로 tensorflow에서는 오류 발생 함\n",
    "# depth는 vocabulary 크기\n",
    "#############################\n",
    "tf.one_hot(indices=token_ids, depth=len(word_to_id))\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_ids가 앞 3개개만 one_hot으로 변경\n",
    "#############################\n",
    "tf.one_hot(indices=token_ids[:3], depth=len(word_to_id))\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모두 길이가 4가 되도록 pad(0) 추가\n",
    "pad_ids = []\n",
    "for line in token_ids:\n",
    "    line = line[:4]\n",
    "    line += [0] * (4 - len(line))\n",
    "    pad_ids.append(line)\n",
    "pad_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "tf_one_hot_encodings = tf.one_hot(indices=pad_ids, depth=len(word_to_id))\n",
    "tf_one_hot_encodings\n",
    "#############################"
   ]
  },
  {
   "source": [
    "# Embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 매트릭스 생성\n",
    "weights = np.random.randint(10, 100, size=(len(word_to_id), 4)) / 100\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 문장 만 numpy array로 변경\n",
    "one_hot_encoding_0 = np.array(one_hot_encodings[0])\n",
    "one_hot_encoding_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_ids[0])\n",
    "print(weights[token_ids[0][0]])\n",
    "print(weights[token_ids[0][1]])\n",
    "print(weights[token_ids[0][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding은 matrix의 특정 row를 선택하는 것과 같은 결과\n",
    "##################\n",
    "np.matmul(one_hot_encoding_0, weights)\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 에서도 tf.keras.layers.Embedding에서도 가능 함\n",
    "# weights 초기화를 위해서 [matrix] 형태로 변환함\n",
    "# embdding을 사용하면 token 번호를 바로 사용가능 함 현재 표준화된 방법\n",
    "embedding = tf.keras.layers.Embedding(len(word_to_id), 4, weights=[weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding(np.array(token_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "tf.gather(weights, np.array(token_ids[0]))\n",
    "##################"
   ]
  }
 ]
}