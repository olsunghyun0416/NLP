{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 한글 폰트 설치"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폰트 설치\n",
    "!apt-get update -qq # 나눔고딕 설치\n",
    "!apt-get install fonts-nanum* -qq\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 폰트 로딩\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()"
   ]
  },
  {
   "source": [
    "# Install"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "source": [
    "# Evn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import zipfile\n",
    "import math\n",
    "import copy\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed initialize\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "source": [
    "# Gensim\n",
    "# https://radimrehurek.com/gensim/index.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "source": [
    "# Tutorial"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미 학습된 model download\n",
    "# wv = api.load('word2vec-google-news-300') # 1.6G\n",
    "wv = api.load('glove-wiki-gigaword-100') # 128M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab 개수 및 최초 20개 출력\n",
    "print(f\"len: {len(wv.vocab)}\")\n",
    "for i, word in enumerate(wv.vocab):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    print(f\"{i:2d}: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar('obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar('banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# king - man + woman by\n",
    "result = wv.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(p1, n1, p2):\n",
    "    result = wv.most_similar(positive=[p2, p1], negative=[n1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# japanese - japan + australia\n",
    "analogy('japanese', 'japan', 'australia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beer - australia + france\n",
    "analogy('beer', 'australia', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinton - reagan + obama\n",
    "analogy('clinton', 'reagan', 'obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pca_scatterplot(model, words=None, n_sample=100):\n",
    "    if not words:\n",
    "        words = np.random.choice(list(model.vocab.keys()), n_sample)\n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    # 폰트\n",
    "    font_name = \"NanumBarunGothic\"\n",
    "\n",
    "    # plot 크기 및 폰트 설정\n",
    "    plt.rc('font', family=font_name)\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False # 한글 폰트 사용시 - 깨지는 문제 해결\n",
    "\n",
    "    word_vectors = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.scatter(word_vectors[:,0], word_vectors[:,1], edgecolors='k', c='r')\n",
    "    for word, (x, y) in zip(words, word_vectors):\n",
    "        plt.text(x, y, word)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_scatterplot(wv, words=['coffee', 'tea', 'beer', 'wine', 'brandy', 'rum', 'champagne', 'water',\n",
    "                         'spaghetti', 'borscht', 'hamburger', 'pizza', 'falafel', 'sushi', 'meatballs',\n",
    "                         'dog', 'horse', 'cat', 'monkey', 'parrot', 'koala', 'lizard',\n",
    "                         'frog', 'toad', 'monkey', 'ape', 'kangaroo', 'wombat', 'wolf',\n",
    "                         'france', 'germany', 'hungary', 'luxembourg', 'australia', 'fiji', 'china',\n",
    "                         'homework', 'assignment', 'problem', 'exam', 'test', 'class',\n",
    "                         'school', 'college', 'university', 'institute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_scatterplot(wv)"
   ]
  },
  {
   "source": [
    "# 한국어 학습\n",
    "# https://wikidocs.net/50739"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행태소분석기 설치\n",
    "!set -x \\\n",
    "&& pip install konlpy \\\n",
    "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "okt = konlpy.tag.Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt.morphs(\"아버지가방에들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 영화 리뷰 데이터 다운로드\n",
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_data = pd.read_csv(\"ratings.txt\", header=0, delimiter='\\t', quoting=3)\n",
    "print(f\"전체 데이터의 개수: {len(nsmc_data)}\")\n",
    "nsmc_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null 제거\n",
    "nsmc_data = nsmc_data.dropna()\n",
    "print(f\"null 제거 후 데이터의 개수: {len(nsmc_data)}\")\n",
    "nsmc_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 이외의 문자 제거\n",
    "nsmc_data['document'] = nsmc_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "nsmc_data.dropna()\n",
    "print(f\"한글 아닌 문자 제거 후 데이터의 개수: {len(nsmc_data)}\")\n",
    "nsmc_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의 (빈도가 너무 많은 단어는 학습에서 제외 함)\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okt 형태소 분석기를 이용해 형태소 단위로 분할 (이때 불용어 제거)\n",
    "tokens = []\n",
    "for i, document in enumerate(tqdm(nsmc_data['document'], total=len(nsmc_data))):\n",
    "    line = []\n",
    "    line = okt.morphs(document)\n",
    "    line = [word for word in line if not word in stopwords]\n",
    "    tokens.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokens))\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim 학습\n",
    "word2vec_100 = gensim.models.Word2Vec(sentences=tokens, size=100, window=5, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(word2vec_100.wv.vocab)\n",
    "len(words), words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = word2vec_100.wv.most_similar(\"영화\")\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = word2vec_100.wv.most_similar(\"최민수\")\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = word2vec_100.wv.most_similar(\"장동건\")\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설경구 - 송윤아 + 고소영\n",
    "result = word2vec_100.wv.most_similar(positive=['고소영', '설경구'], negative=['송윤아'])\n",
    "result"
   ]
  }
 ]
}