{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 한글 폰트 설치"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폰트 설치\n",
    "!apt-get update -qq # 나눔고딕 설치\n",
    "!apt-get install fonts-nanum* -qq\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 폰트 로딩\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()"
   ]
  },
  {
   "source": [
    "# Istall"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "source": [
    "# Evn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import zipfile\n",
    "import math\n",
    "import copy\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed initialize\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google drive mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dir\n",
    "data_dir = '/content/drive/MyDrive/Colab Notebooks'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quora dir\n",
    "quora_dir = os.path.join(data_dir, 'quora')\n",
    "if not os.path.exists(quora_dir):\n",
    "    os.makedirs(quora_dir)\n",
    "os.listdir(quora_dir)"
   ]
  },
  {
   "source": [
    "# Vocabualry & config"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(os.path.join(data_dir, 'ko_32000.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(vocab)  # number of vocabulary\n",
    "n_seq_1 = 26  # number of sequence 1\n",
    "n_seq_2 = 27  # number of sequence 2\n",
    "d_model = 256  # dimension of model\n",
    "n_out = 2  # number of output class"
   ]
  },
  {
   "source": [
    "# 다운로드\n",
    "# https://github.com/songys/Question_pair"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/songys/Question_pair/master/kor_pair_train.csv\n",
    "!wget https://raw.githubusercontent.com/songys/Question_pair/master/kor_Pair_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move('kor_pair_train.csv', os.path.join(quora_dir, 'kor_pair_train.csv')) # os.path.join -> 경로를 병합하여 새 경로 생성\n",
    "shutil.move('kor_Pair_test.csv', os.path.join(quora_dir, 'kor_Pair_test.csv'))\n",
    "os.listdir(quora_dir)"
   ]
  },
  {
   "source": [
    "# 데이터 분석"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data load\n",
    "# os.path.join -> 경로를 병합하여 새 경로 생성\n",
    "df_train = pd.read_csv(os.path.join(quora_dir, 'kor_pair_train.csv'), delimiter=',')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train null 데이터 제거\n",
    "df_train = df_train.dropna() # dropna() -> 결측값 삭제\n",
    "df_train"
   ]
  },
  {
   "source": [
    "# Char"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. question1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char 길이 데이터\n",
    "# 각 인덱스마다 띄어쓰기를 포함한 문장의 길이를 나타냄\n",
    "char_len = df_train['question1'].astype(\"str\").apply(len)\n",
    "char_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(char_len, bins=60, range=[0, 60], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of char')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of char')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"char 길이 최대:    {np.max(char_len):4d}\")\n",
    "print(f\"char 길이 최소:    {np.min(char_len):4d}\")\n",
    "print(f\"char 길이 평균:    {np.mean(char_len):7.2f}\")\n",
    "print(f\"char 길이 표준편차: {np.std(char_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(char_len, 25)\n",
    "percentile50 = np.percentile(char_len, 50)\n",
    "percentile75 = np.percentile(char_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"char 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"char 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"char 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"char IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"char MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(char_len, labels=['char counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(char_len, labels=['char counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 2. question2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char 길이 데이터\n",
    "char_len = df_train['question2'].astype(\"str\").apply(len)\n",
    "char_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(char_len, bins=60, range=[0, 60], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of char')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of char')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"char 길이 최대:    {np.max(char_len):4d}\")\n",
    "print(f\"char 길이 최소:    {np.min(char_len):4d}\")\n",
    "print(f\"char 길이 평균:    {np.mean(char_len):7.2f}\")\n",
    "print(f\"char 길이 표준편차: {np.std(char_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(char_len, 25)\n",
    "percentile50 = np.percentile(char_len, 50)\n",
    "percentile75 = np.percentile(char_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"char 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"char 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"char 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"char IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"char MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(char_len, labels=['char counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char 길이 데이터\n",
    "char_len = df_train['question2'].astype(\"str\").apply(len)\n",
    "char_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(char_len, bins=60, range=[0, 60], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of char')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of char')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"char 길이 최대:    {np.max(char_len):4d}\")\n",
    "print(f\"char 길이 최소:    {np.min(char_len):4d}\")\n",
    "print(f\"char 길이 평균:    {np.mean(char_len):7.2f}\")\n",
    "print(f\"char 길이 표준편차: {np.std(char_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(char_len, 25)\n",
    "percentile50 = np.percentile(char_len, 50)\n",
    "percentile75 = np.percentile(char_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"char 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"char 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"char 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"char IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"char MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(char_len, labels=['char counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. question1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 길이 데이터\n",
    "# 0번째 인덱스 <1000일 만난 여자친구와 이별>의 단어 개수가 4개, 이런식으로 인덱스마다 단어의 개수를 셈\n",
    "word_len = df_train['question1'].astype(str).apply(lambda x:len(x.split(' ')))\n",
    "word_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(word_len, bins=15, range=[0, 15], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of word')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of word')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"word 길이 최대:    {np.max(word_len):4d}\")\n",
    "print(f\"word 길이 최소:    {np.min(word_len):4d}\")\n",
    "print(f\"word 길이 평균:    {np.mean(word_len):7.2f}\")\n",
    "print(f\"word 길이 표준편차: {np.std(word_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(word_len, 25)\n",
    "percentile50 = np.percentile(word_len, 50)\n",
    "percentile75 = np.percentile(word_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"word 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"word 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"word 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"word IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"word MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(word_len, labels=['word counts'], showmeans=True)\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# 2. question2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 길이 데이터\n",
    "word_len = df_train['question2'].astype(str).apply(lambda x:len(x.split(' ')))\n",
    "word_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(word_len, bins=15, range=[0, 15], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of word')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of word')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"word 길이 최대:    {np.max(word_len):4d}\")\n",
    "print(f\"word 길이 최소:    {np.min(word_len):4d}\")\n",
    "print(f\"word 길이 평균:    {np.mean(word_len):7.2f}\")\n",
    "print(f\"word 길이 표준편차: {np.std(word_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(word_len, 25)\n",
    "percentile50 = np.percentile(word_len, 50)\n",
    "percentile75 = np.percentile(word_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"word 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"word 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"word 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"word IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"word MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(word_len, labels=['word counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Sentencepiece"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. question1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 길이 데이터\n",
    "# 각 인덱스마다 형태소 분석을 한 상태의 단어 개수를 셈\n",
    "spm_len = df_train['question1'].astype(str).apply(lambda x:len(vocab.encode_as_pieces(x))) # x가 question1\n",
    "spm_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(spm_len, bins=30, range=[0, 30], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of spm')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of spm')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"spm 길이 최대:    {np.max(spm_len):4d}\")\n",
    "print(f\"spm 길이 최소:    {np.min(spm_len):4d}\")\n",
    "print(f\"spm 길이 평균:    {np.mean(spm_len):7.2f}\")\n",
    "print(f\"spm 길이 표준편차: {np.std(spm_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(spm_len, 25)\n",
    "percentile50 = np.percentile(spm_len, 50)\n",
    "percentile75 = np.percentile(spm_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"spm 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"spm 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"spm 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"spm IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"spm MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(spm_len, labels=['spm counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 2. question2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 길이 데이터\n",
    "spm_len = df_train['question2'].astype(str).apply(lambda x:len(vocab.encode_as_pieces(x)))\n",
    "spm_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(spm_len, bins=30, range=[0, 30], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of spm')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of spm')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"spm 길이 최대:    {np.max(spm_len):4d}\")\n",
    "print(f\"spm 길이 최소:    {np.min(spm_len):4d}\")\n",
    "print(f\"spm 길이 평균:    {np.mean(spm_len):7.2f}\")\n",
    "print(f\"spm 길이 표준편차: {np.std(spm_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(spm_len, 25)\n",
    "percentile50 = np.percentile(spm_len, 50)\n",
    "percentile75 = np.percentile(spm_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"spm 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"spm 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"spm 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"spm IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"spm MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(spm_len, labels=['spm counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Label"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label count\n",
    "print(f\"같은 질문 개수: {df_train['is_duplicate'].value_counts()[0]}\")\n",
    "print(f\"다른 질문 개수: {df_train['is_duplicate'].value_counts()[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label counter plot\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(6, 5)\n",
    "# https://seaborn.pydata.org/\n",
    "subplt = sns.countplot(df_train['is_duplicate'])"
   ]
  },
  {
   "source": [
    "# Word Cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 합치기\n",
    "train_set = pd.Series(df_train['question1'].tolist() + df_train['question2'].tolist()).astype(str)\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train review documents\n",
    "train_review = [review for review in train_set if type(review) is str]\n",
    "train_review[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(train_review[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud\n",
    "# window: C:/Windows/Fonts/malgun.ttf, mac: /Library/Fonts/AppleGothic.ttf, colab: /usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\n",
    "wordcloud = WordCloud(width=800, height=800, font_path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf').generate(' '.join(train_review))\n",
    "plt.figure(figsize=(10, 10))\n",
    "# https://datascienceschool.net/view-notebook/6e71dbff254542d9b0a054a7c98b34ec/\n",
    "# image 출력, interpolation 이미지 시각화 옵션\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 모델링"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장\n",
    "sentences = [\n",
    "    ['나는 오늘 기분이 좋아', '나는 오늘 우울해'],\n",
    "    ['나는 오늘 행복해', '나는 오늘 즐거워'],\n",
    "]\n",
    "\n",
    "# 출력 정답\n",
    "labels = [0, 1]  # 같음(1), 다름(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장을 띄어쓰기 단위로 분할\n",
    "words = []\n",
    "for pair in sentences:\n",
    "    for sentence in pair:\n",
    "        words.extend(sentence.split())\n",
    "\n",
    "# 중복 단어 제거\n",
    "words = list(dict.fromkeys(words))\n",
    "\n",
    "# 각 단어별 고유한 번호 부여\n",
    "word_to_id = {'[PAD]': 0, '[UNK]': 1}\n",
    "for word in words:\n",
    "    word_to_id[word] = len(word_to_id)\n",
    "\n",
    "# 각 숫자별 단어 부여\n",
    "id_to_word = {_id:word for word, _id in word_to_id.items()}\n",
    "\n",
    "word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 입력 데이터 생성\n",
    "train_inputs_1, train_inputs_2 = [], []\n",
    "for pair in sentences:\n",
    "    train_inputs_1.append([word_to_id[word] for word in pair[0].split()])\n",
    "    train_inputs_2.append([word_to_id[word] for word in pair[1].split()])\n",
    "\n",
    "# train label\n",
    "train_labels = labels\n",
    "\n",
    "# 문장의 길이를 모두 동일하게 변경 (최대길이 4)\n",
    "for row in train_inputs_1:\n",
    "    row += [0] * (4 - len(row))\n",
    "\n",
    "# 문장의 길이를 모두 동일하게 변경 (최대길이 3)\n",
    "for row in train_inputs_2:\n",
    "    row += [0] * (3 - len(row))\n",
    "\n",
    "# train inputs을 numpy array로 변환\n",
    "train_inputs_1 = np.array(train_inputs_1)\n",
    "train_inputs_2 = np.array(train_inputs_2)\n",
    "\n",
    "# 학습용 정답을 numpy array로 변환\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "train_inputs_1, train_inputs_2, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding 생성\n",
    "embedding = tf.keras.layers.Embedding(len(word_to_id), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance abs\n",
    "#hidden_poo1_1 - hidden_pool_2\n",
    "K.abs(hidden_poo1_1 - hidden_pool_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manhattan distance abs\n",
    "distance = K.sum(K.abs(hidden_poo1_1 - hidden_pool_2), axis=-1)\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output value\n",
    "output = K.exp(-distance)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate linearly spaced vector\n",
    "distance = np.linspace(0, 10, 100)\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot\n",
    "# distance가 가까우면 의미가 더 가깝다, (가까우면)비슷하면 1이고, 거리가 멀어질 수록 0에 가까워짐\n",
    "plt.plot(distance, K.exp(-distance))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_vocab, d_model, n_seq_1, n_seq_2):\n",
    "    \"\"\"\n",
    "    문장 유사도 비교 모델\n",
    "    :param n_vocab: vocabulary 단어 수\n",
    "    :param d_model: 단어를 의미하는 벡터의 차원 수\n",
    "    :param n_seq_1: 문장 1 길이 (단어 수)\n",
    "    :param n_seq_2: 문장 2 길이 (단어 수)\n",
    "    \"\"\"\n",
    "    inputs_1 = tf.keras.layers.Input((n_seq_1,))  # (bs, n_seq_1)\n",
    "    inputs_2 = tf.keras.layers.Input((n_seq_2,))  # (bs, n_seq_2)\n",
    "    ##########################################\n",
    "    # 입력 단어를 vector로 변환\n",
    "    embedding = tf.keras.layers.Embedding(n_vocab, d_model)\n",
    "    hidden_1 = embedding(inputs_1)  # (bs, n_seq_1, d_model)\n",
    "    hidden_2 = embedding(inputs_2)  # (bs, n_seq_2, d_model)\n",
    "\n",
    "    # RNN, CNN, Dense\n",
    "    \n",
    "    # 각 단어 벡터의 최대값 기준으로 벡터를 더해서 차원을 줄여줌 (문장 vector 생성)\n",
    "    pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "    hidden_pool_1 = pool(hidden_1)  # (bs, d_model)\n",
    "    hidden_pool_2 = pool(hidden_2)  # (bs, d_model)\n",
    "\n",
    "    # distance 계산 ||a - b||\n",
    "    distance = K.sum(K.abs(hidden_pool_1 - hidden_pool_2), axis=-1)\n",
    "    outputs = K.exp(-distance)\n",
    "    ##########################################\n",
    "    # 학습할 모델 선언\n",
    "    model = tf.keras.Model(inputs=(inputs_1, inputs_2), outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(len(word_to_id), 5, 4, 3)\n",
    "# 모델 내용 그래프 출력\n",
    "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "source": [
    "# Sample Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(quora_dir, 'kor_pair_train.csv'), delimiter=',')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(quora_dir, 'kor_Pair_test.csv'), delimiter=',')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name을 지정해줌\n",
    "df_test = df_test[['test_id', 'question1', 'question2', 'is_duplicate']]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.dropna()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤하게 10개만 확인\n",
    "df_train = df_train.sample(10)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤하게 10개만 확인\n",
    "df_test = df_test.sample(10)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, n_seq_1, n_seq_2):\n",
    "    \"\"\"\n",
    "    Quora 학습 데이터 생성\n",
    "    :param df: data frame\n",
    "    :param n_seq_1: number of sequence 1\n",
    "    :param n_seq_2: number of sequence 2\n",
    "    :return inputs_1: input data 1\n",
    "    :return inputs_2: input data 2\n",
    "    :return labels: label data\n",
    "    \"\"\"\n",
    "    inputs_1 = np.zeros((len(df), n_seq_1)).astype(np.int32)\n",
    "    inputs_2 = np.zeros((len(df), n_seq_2)).astype(np.int32)\n",
    "    labels = np.zeros((len(df),))\n",
    "    index = 0\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        # tokens 저장\n",
    "        print()\n",
    "        #################################\n",
    "        is_duplicate = row['is_duplicate']\n",
    "        question1 = row['question1']\n",
    "        question2 = row['question2']\n",
    "        print(is_duplicate, '/', question1, '/', question2)\n",
    "        # 문장을 token으로 변환\n",
    "        tokens_1 = vocab.encode_as_pieces(question1)\n",
    "        print(len(tokens_1), ':', tokens_1)\n",
    "        tokens_2 = vocab.encode_as_pieces(question2)\n",
    "        print(len(tokens_2), ':', tokens_2)\n",
    "        # 문장을 id로 변환\n",
    "        token_ids_1 = vocab.encode_as_ids(question1)\n",
    "        print(len(token_ids_1), ':', token_ids_1)\n",
    "        token_ids_2 = vocab.encode_as_ids(question2)\n",
    "        print(len(token_ids_2), ':', token_ids_2)\n",
    "        # 길이가 길면 길이를 줄임\n",
    "        token_ids_1 = token_ids_1[:n_seq_1]\n",
    "        print(len(token_ids_1), ':', token_ids_1)\n",
    "        token_ids_2 = token_ids_2[:n_seq_2]\n",
    "        print(len(token_ids_2), ':', token_ids_2)\n",
    "        # 길이가 짧으면 늘려줌 (pad(0))\n",
    "        token_ids_1 += [0] * (n_seq_1 - len(token_ids_1))\n",
    "        print(len(token_ids_1), ':', token_ids_1)\n",
    "        token_ids_2 += [0] * (n_seq_2 - len(token_ids_2))\n",
    "        print(len(token_ids_2), ':', token_ids_2)\n",
    "\n",
    "        labels[index] = 1 - is_duplicate  # 0 -> 1, 1 -> 0\n",
    "        inputs_1[index] = token_ids_1\n",
    "        inputs_2[index] = token_ids_2\n",
    "        index += 1\n",
    "        #################################\n",
    "    return inputs_1, inputs_2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 생성\n",
    "train_inputs_1, train_inputs_2, train_labels = load_data(df_train, n_seq_1, n_seq_2)\n",
    "train_inputs_1, train_inputs_2, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data 생성\n",
    "test_inputs_1, test_inputs_2, test_labels = load_data(df_test, n_seq_1, n_seq_2)\n",
    "test_inputs_1, test_inputs_2, test_labels"
   ]
  },
  {
   "source": [
    "# 2. 학습"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(len(vocab), d_model, n_seq_1, n_seq_2)\n",
    "# 모델 내용 그래프 출력\n",
    "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 loss, optimizer, metric 정의\n",
    "# mean_squared_error -> mse\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=50)\n",
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(os.path.join(quora_dir, 'stub.hdf5'),\n",
    "                                                  monitor='val_binary_accuracy',\n",
    "                                                  verbose=1,\n",
    "                                                  save_best_only=True,\n",
    "                                                  mode=\"max\",\n",
    "                                                  save_freq=\"epoch\",\n",
    "                                                  save_weights_only=True)\n",
    "# csv logger\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(quora_dir, 'stub.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = model.fit((train_inputs_1, train_inputs_2),\n",
    "                    train_labels,\n",
    "                    validation_data=((test_inputs_1, test_inputs_2), test_labels),\n",
    "                    epochs=100,\n",
    "                    batch_size=256,\n",
    "                    callbacks=[early_stopping, save_weights, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['binary_accuracy'], 'g-', label='acc')\n",
    "plt.plot(history.history['val_binary_accuracy'], 'k--', label='val_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 3. Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(len(vocab), d_model, n_seq_1, n_seq_2)\n",
    "# train weight로 초기화\n",
    "model.load_weights(os.path.join(quora_dir, 'stub.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "logits = model.predict((test_inputs_1, test_inputs_2))\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5를 기준으로 (0, 1) 결정\n",
    "test_preds = (0.5 < logits).astype(np.int)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix 계산\n",
    "confusion_matrix = np.zeros((2, 2)).astype(np.int)\n",
    "for y_true, y_pred in zip(test_labels, test_preds):\n",
    "    confusion_matrix[int(y_true), int(y_pred)] += 1\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score 계산\n",
    "tp = confusion_matrix[1, 1]\n",
    "tn = confusion_matrix[0, 0]\n",
    "fp = confusion_matrix[0, 1]\n",
    "fn = confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
    "print(f'accuracy: {accuracy}')\n",
    "precision = (tp) / max(tp + fp, 1)\n",
    "print(f'precision: {precision}')\n",
    "recall = (tp) / max(tp + fn, 1)\n",
    "print(f'recall: {recall}')\n",
    "f1 = 2 * (precision * recall) / max(precision + recall, 1)\n",
    "print(f'f1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict(model, n_seq_1, string1, n_seq_2, string2):\n",
    "    \"\"\"\n",
    "    입력에 대한 답변 생성하는 함수\n",
    "    :param model: model\n",
    "    :param n_seq_1: 입력 개수 1\n",
    "    :param string1: 입력 문자열 1\n",
    "    :param n_seq_1: 입력 개수 3\n",
    "    :param string2: 입력 문자열 2\n",
    "    \"\"\"\n",
    "    ###############################\n",
    "    # token 생성: <string 1 tokens>, [PAD] tokens\n",
    "    token1 = vocab.encode_as_ids(string1)\n",
    "    token1 = token1[:n_seq_1]\n",
    "    token1 += [0] * (n_seq_1 - len(token1))\n",
    "    print(token1)\n",
    "\n",
    "    # token 생성: <string 2 tokens>, [PAD] tokens\n",
    "    token2 = vocab.encode_as_ids(string2)\n",
    "    token2 = token2[:n_seq_2]\n",
    "    token2 += [0] * (n_seq_2 - len(token2))\n",
    "    print(token2)\n",
    "    ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = '나는 오늘 기분이 좋아'\n",
    "string2 = '나는 오늘 우울해'\n",
    "do_predict(model, n_seq_1, string1, n_seq_2, string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"string #1 > \", end=\"\")\n",
    "    string1 = str(input())\n",
    "    if len(string1) == 0:\n",
    "        break\n",
    "    print(\"string #2 > \", end=\"\")\n",
    "    string2 = str(input())\n",
    "    if len(string2) == 0:\n",
    "        break\n",
    "    print(f\"output > {do_predict(model, n_seq_1, string1, n_seq_2, string2)}\")"
   ]
  }
 ]
}