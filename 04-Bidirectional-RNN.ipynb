{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Evn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import zipfile\n",
    "import math\n",
    "import copy\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed initialize\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "source": [
    "# 입력 및 Vocab"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장\n",
    "sentences = [\n",
    "    '나는 오늘 기분이 좋아 나는 오늘 우울해'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장을 띄어쓰기 단위로 분할\n",
    "words = []\n",
    "for sentence in sentences:\n",
    "    words.extend(sentence.split())\n",
    "\n",
    "# 중복 단어 제거\n",
    "words = list(dict.fromkeys(words))\n",
    "\n",
    "# 각 단어별 고유한 번호 부여\n",
    "word_to_id = {'[PAD]': 0, '[UNK]': 1}\n",
    "for word in words:\n",
    "    word_to_id[word] = len(word_to_id)\n",
    "\n",
    "# 각 숫자별 단어 부여\n",
    "id_to_word = {_id:word for word, _id in word_to_id.items()}\n",
    "\n",
    "word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 입력 데이터 생성\n",
    "train_inputs = []\n",
    "for sentence in sentences:\n",
    "    train_inputs.append([word_to_id[word] for word in sentence.split()])\n",
    "\n",
    "# train inputs을 numpy array로 변환\n",
    "train_inputs = np.array(train_inputs)\n",
    "\n",
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "embedding = tf.keras.layers.Embedding(len(word_to_id), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어벡터\n",
    "hidden = embedding(train_inputs)\n",
    "hidden"
   ]
  },
  {
   "source": [
    "# Bidirectional RNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. return sequence=False, return_state=False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi rnn\n",
    "# rnn_11 = tf.keras.layers.SimpleRNN(units=5)\n",
    "bi_rnn_11 = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=5))\n",
    "output_11 = bi_rnn_11(hidden)  # (bs, units * 2)\n",
    "print(output_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi rnn weights\n",
    "weights = bi_rnn_11.get_weights()\n",
    "Wx = weights[0]\n",
    "Wh = weights[1]\n",
    "b = weights[2]\n",
    "print(Wx.shape)  # (d_model, unit)\n",
    "print(Wh.shape)  # (unit, unit)\n",
    "print(b.shape)  # (unit,)"
   ]
  },
  {
   "source": [
    "# 2. return sequence=True, return_state=False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_sequences=True)\n",
    "bi_rnn_12 = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=5, return_sequences=True))\n",
    "output_12 = bi_rnn_12(hidden)  # (bs, seq, units* 2)\n",
    "print(output_12)"
   ]
  },
  {
   "source": [
    "# 3. return sequence=False, return_state=True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_state=True)\n",
    "bi_rnn_13 = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=5, return_state=True))\n",
    "output_13, fw_h_13, bw_h_13 = bi_rnn_13(hidden)  # (bs, units * 2), (bs, units), (bs, units)\n",
    "print(output_13)\n",
    "print(fw_h_13)\n",
    "print(bw_h_13)"
   ]
  },
  {
   "source": [
    "# 4. return sequence=True, return_state=True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_sequences=True, return_state=True)\n",
    "bi_rnn_14 = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=5, return_sequences=True, return_state=True))\n",
    "output_14, fw_h_14, bw_h_14 = bi_rnn_14(hidden)  # (bs, seq, units * 2), (bs, units), (bs, units)\n",
    "print(output_14)\n",
    "print(fw_h_14)\n",
    "print(bw_h_14)"
   ]
  },
  {
   "source": [
    "# 5. init hidden state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_rnn_11 with fw_h_13, bw_h_13\n",
    "bi_rnn_11(hidden, initial_state=[fw_h_13, bw_h_13])  # (bs, units * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_rnn_12 with fw_h_14, bw_h_14\n",
    "bi_rnn_12(hidden, initial_state=[fw_h_14, bw_h_14])  # (bs, n_seq, units * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_rnn_13 with fw_h_13, bw_h_13\n",
    "bi_rnn_13(hidden, initial_state=[fw_h_13, bw_h_13])  # (bs, units * 2), (bs, units), (bs, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_rnn_14 with fw_h_14, bw_h_14\n",
    "bi_rnn_14(hidden, initial_state=[fw_h_14, bw_h_14])  # (bs, n_seq, units * 2), (bs, units), (bs, units)"
   ]
  },
  {
   "source": [
    "# Bidirectional LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. return sequence=False, return_state=False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm\n",
    "bi_lstm_11 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=5))\n",
    "output_11 = bi_lstm_11(hidden)  # (bs, units * 2)\n",
    "print(output_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm weights\n",
    "weights = bi_lstm_11.get_weights()\n",
    "Wx = weights[0]\n",
    "Wh = weights[1]\n",
    "b = weights[2]\n",
    "print(Wx.shape)  # (d_model, unit * 4) (Wxf, Wxi, Wxc, Wxo)\n",
    "print(Wh.shape)  # (unit, unit * 4) (Whf, Whi, Whc, Who)\n",
    "print(b.shape)  # (unit * 4) (bf, bi, bc, bo)"
   ]
  },
  {
   "source": [
    "# 2. return sequence=True, return_state=False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_sequences=True)\n",
    "bi_lstm_12 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=5, return_sequences=True))\n",
    "output_12 = bi_lstm_12(hidden)  # (bs, seq, units * 2)\n",
    "print(output_12)"
   ]
  },
  {
   "source": [
    "# 3. return sequence=False, return_state=True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_state=True)\n",
    "bi_lstm_13 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=5, return_state=True))\n",
    "output_13, fw_h_13, fw_c_13, bw_h_13, bw_c_13 = bi_lstm_13(hidden)  # (bs, units * 2), (bs, units), (bs, units), (bs, units), (bs, units)\n",
    "print(output_13)\n",
    "print(fw_h_13)\n",
    "print(fw_c_13)\n",
    "print(bw_h_13)\n",
    "print(bw_c_13)"
   ]
  },
  {
   "source": [
    "# 4. return sequence=True, return_state=True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_sequences=True, return_state=True)\n",
    "# (return_sequences=True, return_state=True)\n",
    "bi_lstm_14 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=5, return_sequences=True, return_state=True))\n",
    "output_14, fw_h_14, fw_c_14, bw_h_14, bw_c_14 = bi_lstm_14(hidden)  # (bs, seq, units), (bs, units), (bs, units), (bs, units), (bs, units)\n",
    "print(output_14)\n",
    "print(fw_h_14)\n",
    "print(fw_c_14)\n",
    "print(bw_h_14)\n",
    "print(bw_c_14)"
   ]
  },
  {
   "source": [
    "# 5. init hidden state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_lstm_11 with fw_h_13, fw_c_13, bw_h_13, bw_c_13\n",
    "bi_lstm_11(hidden, initial_state=[fw_h_13, fw_c_13, bw_h_13, bw_c_13])  # (bs, units * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_lstm_12 with fw_h_14, fw_c_14, bw_h_14, bw_c_14\n",
    "bi_lstm_12(hidden, initial_state=[fw_h_14, fw_c_14, bw_h_14, bw_c_14])  # (bs, n_seq, units * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_lstm_13 with fw_h_13, fw_c_13, bw_h_13, bw_c_13\n",
    "bi_lstm_13(hidden, initial_state=[fw_h_13, fw_c_13, bw_h_13, bw_c_13])  # (bs, units * 2), (bs, units), (bs, units), (bs, units), (bs, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_lstm_14 with fw_h_14, fw_c_14, bw_h_14, bw_c_14\n",
    "bi_lstm_14(hidden, initial_state=[fw_h_14, fw_c_14, bw_h_14, bw_c_14])  # (bs, n_seq, units * 2), (bs, units), (bs, units), (bs, units), (bs, units)"
   ]
  },
  {
   "source": [
    "# Bidirectional GRU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. return sequence=False, return_state=False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi GRU\n",
    "bi_gru_11 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=5))\n",
    "output_11 = bi_gru_11(hidden)  # (bs, units * 2)\n",
    "print(output_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi GRU weights\n",
    "weights = bi_gru_11.get_weights()\n",
    "Wx = weights[0]\n",
    "Wh = weights[1]\n",
    "b = weights[2]\n",
    "print(Wx.shape)  # (d_model, unit * 3) (Wxr, Wxz, Wxg)\n",
    "print(Wh.shape)  # (unit, unit * 3) (Whr, Whz, Whg)\n",
    "print(b.shape)  # (2, unit * 3) (bxr, bxz, bxg),(bhr, bhz, bhg)"
   ]
  },
  {
   "source": [
    "# 2. return sequence=True, return_state=False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_sequences=True)\n",
    "bi_gru_12 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=5, return_sequences=True))\n",
    "output_12 = bi_gru_12(hidden)  # (bs, seq, units* 2)\n",
    "print(output_12)"
   ]
  },
  {
   "source": [
    "# 3. return sequence=False, return_state=True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_state=True)\n",
    "bi_gru_13 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=5, return_state=True))\n",
    "output_13, fw_h_13, bw_h_13 = bi_gru_13(hidden)  # (bs, units * 2), (bs, units), (bs, units)\n",
    "print(output_13)\n",
    "print(fw_h_13)\n",
    "print(bw_h_13)"
   ]
  },
  {
   "source": [
    "# 4. return sequence=True, return_state=True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (return_sequences=True, return_state=True)\n",
    "bi_gru_14 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=5, return_sequences=True, return_state=True))\n",
    "output_14, fw_h_14, bw_h_14 = bi_gru_14(hidden)  # (bs, seq, units * 2), (bs, units), (bs, units)\n",
    "print(output_14)\n",
    "print(fw_h_14)\n",
    "print(bw_h_14)"
   ]
  },
  {
   "source": [
    "# 5. init hidden state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_gru_11 with fw_h_13, bw_h_13\n",
    "bi_gru_11(hidden, initial_state=[fw_h_13, bw_h_13])  # (bs, units * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_gru_12 with fw_h_14, bw_h_14\n",
    "bi_gru_12(hidden, initial_state=[fw_h_14, bw_h_13])  # (bs, n_seq, units * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_gru_13 with fw_h_13, bw_h_13\n",
    "bi_gru_13(hidden, initial_state=[fw_h_13, bw_h_13])  # (bs, units * 2), (bs, units), (bs, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_gru_14 with fw_h_14, bw_h_14\n",
    "bi_gru_14(hidden, initial_state=[fw_h_14, bw_h_14])  # (bs, n_seq, units * 2), (bs, units), (bs, units)"
   ]
  },
  {
   "source": [
    "# RNN 모델"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_vocab, d_model, n_seq, n_out):\n",
    "    \"\"\"\n",
    "    RNN 모델\n",
    "    :param n_vocab: vocabulary 단어 수\n",
    "    :param d_model: 단어를 의미하는 벡터의 차원 수\n",
    "    :param n_seq: 문장길이 (단어 수)\n",
    "    :param n_out: 예측할 class 개수\n",
    "    \"\"\"\n",
    "    input = tf.keras.layers.Input(shape=(n_seq,))\n",
    "\n",
    "    embedding = tf.keras.layers.Embedding(n_vocab, d_model)  # (n_vocab x d_model)\n",
    "    hidden = embedding(input)  # (bs, 1, d_model)\n",
    "\n",
    "    ########################################\n",
    "    hidden = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=128, return_sequences=True))(hidden)  # (bs, 128)\n",
    "    hidden = tf.keras.layers.SimpleRNN(units=256, return_sequences=True)(hidden)\n",
    "    # rnn_1 = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=128, return_sequences=True))\n",
    "    # hidden = rnn_1(hidden)  # (bs, 128)\n",
    "    # rnn_2 = tf.keras.layers.SimpleRNN(units=128, return_sequences=True)\n",
    "    # hidden = rnn_2(hidden)\n",
    "    ########################################\n",
    "\n",
    "    output = tf.keras.layers.Dense(n_out, activation=tf.nn.softmax)(hidden)  # (bs, 1, n_vocab)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(len(word_to_id), 8, 7, 2)\n",
    "# 모델 내용 그래프 출력\n",
    "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(train_inputs)"
   ]
  }
 ]
}