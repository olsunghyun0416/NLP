{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 한글 폰트 설치"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "zsh:1: command not found: apt-get\n",
      "zsh:1: no matches found: fonts-nanum*\n"
     ]
    }
   ],
   "source": [
    "# 폰트 설치\n",
    "!apt-get update -qq # 나눔고딕 설치\n",
    "!apt-get install fonts-nanum* -qq\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 폰트 로딩\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()"
   ]
  },
  {
   "source": [
    "# Install"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "source": [
    "# Evn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import zipfile\n",
    "import math\n",
    "import copy\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 매트폴립같은거\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed initialize\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google drive mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dir\n",
    "data_dir = '/content/drive/MyDrive/Colab Notebooks/kowiki' # change 'content/ ~ /kowiki' to your drive file path\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsmc dir\n",
    "nsmc_dir = os.path.join(data_dir, 'nsmc')\n",
    "if not os.path.exists(nsmc_dir):\n",
    "    os.makedirs(nsmc_dir)\n",
    "os.listdir(nsmc_dir)"
   ]
  },
  {
   "source": [
    "# Vocabulary & config"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(os.path.join(data_dir, 'ko_32000.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(vocab)  # number of vocabulary\n",
    "n_seq = 47  # number of sequence\n",
    "d_model = 256  # dimension of model => 단어 백터의 차원수\n",
    "n_out = 2  # number of output class"
   ]
  },
  {
   "source": [
    "# 모델링"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장\n",
    "sentences = [\n",
    "    '나는 오늘 기분이 좋아',\n",
    "    '나는 오늘 우울해'\n",
    "]\n",
    "\n",
    "# 출력 정답\n",
    "labels = [1, 0]  # 긍정(1), 부정(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장을 띄어쓰기 단위로 분할\n",
    "words = []\n",
    "for sentence in sentences:\n",
    "    words.extend(sentence.split())\n",
    "\n",
    "# 중복 단어 제거\n",
    "words = list(dict.fromkeys(words))\n",
    "\n",
    "# 각 단어별 고유한 번호 부여\n",
    "word_to_id = {'[PAD]': 0, '[UNK]': 1}\n",
    "for word in words:\n",
    "    word_to_id[word] = len(word_to_id)\n",
    "\n",
    "# 각 숫자별 단어 부여\n",
    "id_to_word = {_id:word for word, _id in word_to_id.items()}\n",
    "\n",
    "word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 입력 데이터 생성\n",
    "train_inputs = []\n",
    "for sentence in sentences:\n",
    "    train_inputs.append([word_to_id[word] for word in sentence.split()])\n",
    "\n",
    "# train label\n",
    "train_labels = labels\n",
    "\n",
    "# 문장의 길이를 모두 동일하게 변경 (최대길이 4)\n",
    "for row in train_inputs:\n",
    "    row += [0] * (4 - len(row))\n",
    "\n",
    "# train inputs을 numpy array로 변환\n",
    "train_inputs = np.array(train_inputs)\n",
    "\n",
    "# 학습용 정답을 numpy array로 변환\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "train_inputs, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 단어를 vector로 변환\n",
    "embedding = tf.keras.layers.Embedding(len(word_to_id), 5)\n",
    "hidden = embedding(train_inputs)\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어 벡터의 최대값 기준으로 벡터를 더해서 차원을 줄여줌 (문장 vector 생성)\n",
    "pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "hidden_pool = pool(hidden)\n",
    "hidden_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 vector를 이용해서 긍정(1), 부정(0) 확률값 예측\n",
    "# 2가 3으로 바뀌면 밑에 열 벡터가 3으로 늘어남\n",
    "linear = tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "outputs = linear(hidden_pool)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측을 위한 wegiths\n",
    "# 왼쪽 열(claas[0])이 첫번째 열에대한 백터에 가까운지 오른쪽 백터에 가까운지에 따라 왼쪽이 더 크면 두 값이 비슷하다\n",
    "weights, bias = linear.get_weights()\n",
    "weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_vocab, d_model, n_seq, n_out):\n",
    "    \"\"\"\n",
    "    문장의 감정분류 모델\n",
    "    :param n_vocab: vocabulary 단어 수\n",
    "    :param d_model: 단어를 의미하는 벡터의 차원 수\n",
    "    :param n_seq: 문장길이 (단어 수)\n",
    "    :param n_out: 예측할 class 개수\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input((n_seq,))  # (bs, n_seq)\n",
    "    ######################################################\n",
    "\n",
    "    # 입력 단어를 vector로 변환\n",
    "    embedding = tf.keras.layers.Embedding(n_vocab, d_model)\n",
    "    hidden = embedding(inputs)  # (bs, n_seq, d_model)\n",
    "\n",
    "    # RNN, CNN, Dense\n",
    "\n",
    "    # 각 단어 벡터의 최대값 기준으로 벡터를 더해서 차원을 줄여줌 (문장 vector 생성)\n",
    "    pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "    hidden_pool = pool(hidden)  # (bs, d_model)\n",
    "\n",
    "    # 문장 vector를 이용해서 긍정(1), 부정(0) 확률값 예측\n",
    "    linear = tf.keras.layers.Dense(n_out, activation=tf.nn.softmax)\n",
    "    outputs = linear(hidden_pool)  # (bs, n_out)\n",
    "    \n",
    "    ######################################################\n",
    "    # 학습할 모델 선언\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(len(word_to_id), 8, 4, 2)\n",
    "# 모델 내용 그래프 출력\n",
    "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(train_inputs)"
   ]
  },
  {
   "source": [
    "# 다운로드\n",
    "# https://github.com/e9t/nsmc"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/e9t/nsmc/raw/master/ratings_train.txt\n",
    "!wget https://github.com/e9t/nsmc/raw/master/ratings_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move('ratings_train.txt', os.path.join(nsmc_dir, 'ratings_train.txt'))\n",
    "shutil.move('ratings_test.txt', os.path.join(nsmc_dir, 'ratings_test.txt'))\n",
    "os.listdir(nsmc_dir)"
   ]
  },
  {
   "source": [
    "# 데이터 분석"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data load\n",
    "df_train = pd.read_csv(os.path.join(nsmc_dir, 'ratings_train.txt'), delimiter='\\t')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train null 데이터 제거\n",
    "df_train = df_train.dropna()\n",
    "df_train"
   ]
  },
  {
   "source": [
    "# 1. Char "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char 길이 데이터\n",
    "char_len = df_train[\"document\"].astype(\"str\").apply(len)\n",
    "char_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(char_len, bins=200, range=[0, 200], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of char')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of char')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"char 길이 최대:    {np.max(char_len):4d}\")\n",
    "print(f\"char 길이 최소:    {np.min(char_len):4d}\")\n",
    "print(f\"char 길이 평균:    {np.mean(char_len):7.2f}\")\n",
    "print(f\"char 길이 표준편차: {np.std(char_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(char_len, 25)\n",
    "percentile50 = np.percentile(char_len, 50)\n",
    "percentile75 = np.percentile(char_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"char 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"char 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"char 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"char IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"char MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(char_len, labels=['char counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 2. word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 길이 데이터\n",
    "word_len = df_train['document'].astype(str).apply(lambda x:len(x.split(' ')))\n",
    "word_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(word_len, bins=50, range=[0, 50], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of word')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of word')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"word 길이 최대:    {np.max(word_len):4d}\")\n",
    "print(f\"word 길이 최소:    {np.min(word_len):4d}\")\n",
    "print(f\"word 길이 평균:    {np.mean(word_len):7.2f}\")\n",
    "print(f\"word 길이 표준편차: {np.std(word_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(word_len, 25)\n",
    "percentile50 = np.percentile(word_len, 50)\n",
    "percentile75 = np.percentile(word_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"word 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"word 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"word 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"word IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"word MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(word_len, labels=['word counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 3. SentecePiece"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 길이 데이터\n",
    "spm_len = df_train['document'].astype(str).apply(lambda x:len(vocab.encode_as_pieces(x)))\n",
    "spm_len.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(spm_len, bins=110, range=[0, 110], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Lengh of spm')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of spm')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이\n",
    "print(f\"spm 길이 최대:    {np.max(spm_len):4d}\")\n",
    "print(f\"spm 길이 최소:    {np.min(spm_len):4d}\")\n",
    "print(f\"spm 길이 평균:    {np.mean(spm_len):7.2f}\")\n",
    "print(f\"spm 길이 표준편차: {np.std(spm_len):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(spm_len, 25)\n",
    "percentile50 = np.percentile(spm_len, 50)\n",
    "percentile75 = np.percentile(spm_len, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"spm 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"spm 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"spm 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"spm IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"spm MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(spm_len, labels=['spm counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 4. Label"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label count\n",
    "print(f\"부정 리뷰 개수: {df_train['label'].value_counts()[0]}\")\n",
    "print(f\"긍정 리뷰 개수: {df_train['label'].value_counts()[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label counter plot\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(6, 5)\n",
    "# https://seaborn.pydata.org/\n",
    "subplt = sns.countplot(df_train['label'])"
   ]
  },
  {
   "source": [
    "# 5. Word Cloud"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train review documents\n",
    "train_review = [review for review in df_train['document'] if type(review) is str]\n",
    "train_review[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(train_review[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud\n",
    "# window: C:/Windows/Fonts/malgun.ttf, mac: /Library/Fonts/AppleGothic.ttf, colab: /usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\n",
    "wordcloud = WordCloud(width=800, height=800, font_path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf').generate(' '.join(train_review))\n",
    "plt.figure(figsize=(10, 10))\n",
    "# https://datascienceschool.net/view-notebook/6e71dbff254542d9b0a054a7c98b34ec/\n",
    "# image 출력, interpolation 이미지 시각화 옵션\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Sample Data Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data load\n",
    "df_train = pd.read_csv(os.path.join(nsmc_dir, 'ratings_train.txt'), delimiter='\\t')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train null 데이터 제거\n",
    "df_train = df_train.dropna()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data load\n",
    "df_test = pd.read_csv(os.path.join(nsmc_dir, 'ratings_test.txt'), delimiter='\\t')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train null 데이터 제거\n",
    "df_test = df_test.dropna()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤하게 10개만 확인\n",
    "df_train = df_train.sample(10)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤하게 10개만 확인\n",
    "df_test = df_test.sample(10)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, n_seq):\n",
    "    \"\"\"\n",
    "    NSMC 학습 데이터 생성\n",
    "    :param df: data frame\n",
    "    :param n_seq: number of sequence\n",
    "    :return inputs: input data\n",
    "    :return labels: label data\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = np.zeros((len(df), n_seq)).astype(np.int32) # 0으로 채워 넣는것\n",
    "    labels = np.zeros((len(df),))\n",
    "    index = 0\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        # tokens 저장\n",
    "        ######################################\n",
    "        print()\n",
    "        label = row['label']\n",
    "        document = row['document']\n",
    "        print(label, document)\n",
    "        tokens = vocab.encode_as_pieces(document)\n",
    "        print(len(tokens), ':', tokens)\n",
    "        token_ids = vocab.encode_as_ids(document)\n",
    "        print(len(token_ids), ':', token_ids)\n",
    "        # 긴 토큰은 길이를 줄임\n",
    "        token_ids = token_ids[:n_seq]\n",
    "        print(len(token_ids), ':', token_ids)\n",
    "        # 짧은 토큰은 pad 추가\n",
    "        token_ids += [0] * (n_seq - len(token_ids))\n",
    "        print(len(token_ids), ':', token_ids)\n",
    "        # 값 저장\n",
    "        labels[index] = label\n",
    "        inputs[index] = token_ids\n",
    "        index += 1\n",
    "        ######################################\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 생성\n",
    "train_inputs, train_labels = load_data(df_train, n_seq)\n",
    "train_inputs, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data 생성\n",
    "test_inputs, test_labels = load_data(df_test, n_seq)\n",
    "test_inputs, test_labels"
   ]
  },
  {
   "source": [
    "# 2. 학습"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(len(vocab), d_model, n_seq, n_out)\n",
    "# 모델 내용 그래프 출력\n",
    "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 loss, optimizer, metric 정의\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(train_inputs, train_labels,\n",
    "                    validation_data=(test_inputs, test_labels),\n",
    "                    epochs=100,\n",
    "                    batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], 'g-', label='acc')\n",
    "plt.plot(history.history['val_accuracy'], 'k--', label='val_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 3. 학습2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(len(vocab), d_model, n_seq, n_out)\n",
    "# 모델 내용 그래프 출력\n",
    "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 loss, optimizer, metric 정의\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping => val_accuracy가 20번 이상 좋아지지 않으면 멈춰라. 학습할 필요가 없는 부분을 학습하지 않게 해줌\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "# save weights callback => weight를 저장하기 위한 부분\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(os.path.join(nsmc_dir, 'stub.hdf5'),\n",
    "                                                  monitor='val_accuracy',\n",
    "                                                  verbose=1,\n",
    "                                                  save_best_only=True,\n",
    "                                                  mode=\"max\",\n",
    "                                                  save_freq=\"epoch\",\n",
    "                                                  save_weights_only=True)\n",
    "# csv logger\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(nsmc_dir, 'stub.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(train_inputs,\n",
    "                    train_labels,\n",
    "                    validation_data=(test_inputs, test_labels),\n",
    "                    epochs=100,\n",
    "                    batch_size=256,\n",
    "                    callbacks=[early_stopping, save_weights, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], 'g-', label='acc')\n",
    "plt.plot(history.history['val_accuracy'], 'k--', label='val_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# 4. Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = build_model(n_vocab, d_model, n_seq, n_out)\n",
    "# train weight로 초기화\n",
    "model.load_weights(os.path.join(nsmc_dir, 'stub.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "logits = model.predict(test_inputs)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률 최대 값을 예측으로 사용\n",
    "test_preds = np.argmax(logits, axis=-1)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix = np.zeros((n_out, n_out)).astype(np.int)\n",
    "for y_true, y_pred in zip(test_labels, test_preds):\n",
    "    confusion_matrix[int(y_true), int(y_pred)] += 1\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy, precision, recall, f1\n",
    "tp = confusion_matrix[1, 1]\n",
    "tn = confusion_matrix[0, 0]\n",
    "fp = confusion_matrix[0, 1]\n",
    "fn = confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (tp + tn) / max((tp + tn + fp + fn), 1)\n",
    "print(f'accuracy: {accuracy}')\n",
    "precision = (tp) / max((tp + fp), 1)\n",
    "print(f'precision: {precision}')\n",
    "recall = (tp) / max((tp + fn), 1)\n",
    "print(f'recall: {recall}')\n",
    "f1 = 2 * (precision * recall) / max((precision + recall), 1)\n",
    "print(f'f1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict(model, n_seq, string):\n",
    "    \"\"\"\n",
    "    입력에 대한 답변 생성하는 함수\n",
    "    :param model: model\n",
    "    :param n_seq: 입력 개수\n",
    "    :param string: 입력 문자열\n",
    "    \"\"\"\n",
    "    # token 생성: <string tokens>, [PAD] tokens\n",
    "    token = vocab.encode_as_ids(string)[:n_seq]\n",
    "    token += [0] * (n_seq - len(token))\n",
    "\n",
    "    y_pred = model.predict(np.array([token]))\n",
    "    y_pred_class = K.argmax(y_pred, axis=-1)\n",
    "\n",
    "    return \"긍정\" if y_pred_class[0] == 1 else \"부정\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '영화 너무 심심해'\n",
    "do_predict(model, n_seq, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"input > \", end=\"\")\n",
    "    string = str(input())\n",
    "    if len(string) == 0:\n",
    "        break\n",
    "    print(f\"output > {do_predict(model, n_seq, string)}\")"
   ]
  }
 ]
}